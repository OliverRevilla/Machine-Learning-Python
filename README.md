# Machine‑Learning‑Python

This repository contains a wide collection of **Jupyter notebooks** that
illustrate common machine‑learning algorithms and techniques using Python.
It serves as a study guide and reference for practitioners looking to
understand how different models work and how to implement them from
scratch or with the help of popular libraries.

## Topics covered

* **Statistical distribution fitting** – fitting Normal and Weibull
  distributions to data and assessing goodness of fit.
* **Regression** – simple linear, multiple linear, polynomial and logistic
  regression; regularisation techniques such as Ridge and Lasso.
* **Classification** – k‑nearest neighbours, Naïve Bayes, decision trees,
  random forests and support vector machines.
* **Clustering and dimensionality reduction** – K‑means clustering and
  principal component analysis (PCA).
* **Ensemble methods** – bagging, boosting and random forests.
* **Model evaluation** – cross‑validation, metrics such as accuracy,
  precision, recall and AUC, and techniques for avoiding overfitting.

## Libraries used

* **scikit‑learn** – provides machine‑learning algorithms and utilities:
  <https://scikit-learn.org/stable/>
* **pandas** and **NumPy** – for data manipulation and numerical
  computation: <https://pandas.pydata.org/> and <https://numpy.org/>
* **Matplotlib** and **Seaborn** – for plotting and visualising datasets
  and model results: <https://matplotlib.org/> and <https://seaborn.pydata.org/>
* **SciPy** – for statistical functions and optimisation:
  <https://scipy.org/>
